{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "partial-garbage",
   "metadata": {},
   "source": [
    "# Movie Recommendation (AutoEncoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mexican-battlefield",
   "metadata": {},
   "source": [
    "## 1. Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "little-passing",
   "metadata": {},
   "source": [
    "This dataset is from grouplen.org. url:https://grouplens.org/datasets/movielens/\n",
    "\n",
    "We take 100k and 1m dataset for the training dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affiliated-upper",
   "metadata": {},
   "source": [
    "## 2. Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dutch-allen",
   "metadata": {},
   "source": [
    "We are going to use AutoEncoder to generate a recommendation system for movies. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "floral-norway",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "satisfactory-vertical",
   "metadata": {},
   "source": [
    "### Import relevent libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "necessary-alignment",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "facial-implement",
   "metadata": {},
   "source": [
    "### Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "statistical-joshua",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = pd.read_csv('ml-1m/movies.dat', sep='::', header= None, engine='python', encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "durable-advertising",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Animation|Children's|Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children's|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "      <td>Comedy|Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3878</th>\n",
       "      <td>3948</td>\n",
       "      <td>Meet the Parents (2000)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3879</th>\n",
       "      <td>3949</td>\n",
       "      <td>Requiem for a Dream (2000)</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3880</th>\n",
       "      <td>3950</td>\n",
       "      <td>Tigerland (2000)</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3881</th>\n",
       "      <td>3951</td>\n",
       "      <td>Two Family House (2000)</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3882</th>\n",
       "      <td>3952</td>\n",
       "      <td>Contender, The (2000)</td>\n",
       "      <td>Drama|Thriller</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3883 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0                                   1                             2\n",
       "0        1                    Toy Story (1995)   Animation|Children's|Comedy\n",
       "1        2                      Jumanji (1995)  Adventure|Children's|Fantasy\n",
       "2        3             Grumpier Old Men (1995)                Comedy|Romance\n",
       "3        4            Waiting to Exhale (1995)                  Comedy|Drama\n",
       "4        5  Father of the Bride Part II (1995)                        Comedy\n",
       "...    ...                                 ...                           ...\n",
       "3878  3948             Meet the Parents (2000)                        Comedy\n",
       "3879  3949          Requiem for a Dream (2000)                         Drama\n",
       "3880  3950                    Tigerland (2000)                         Drama\n",
       "3881  3951             Two Family House (2000)                         Drama\n",
       "3882  3952               Contender, The (2000)                Drama|Thriller\n",
       "\n",
       "[3883 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "architectural-generic",
   "metadata": {},
   "outputs": [],
   "source": [
    "users = pd.read_csv('ml-1m/users.dat', sep='::', header= None, engine='python', encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "statutory-commitment",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>56</td>\n",
       "      <td>16</td>\n",
       "      <td>70072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>15</td>\n",
       "      <td>55117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>M</td>\n",
       "      <td>45</td>\n",
       "      <td>7</td>\n",
       "      <td>02460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>20</td>\n",
       "      <td>55455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6035</th>\n",
       "      <td>6036</td>\n",
       "      <td>F</td>\n",
       "      <td>25</td>\n",
       "      <td>15</td>\n",
       "      <td>32603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6036</th>\n",
       "      <td>6037</td>\n",
       "      <td>F</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>76006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6037</th>\n",
       "      <td>6038</td>\n",
       "      <td>F</td>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>14706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6038</th>\n",
       "      <td>6039</td>\n",
       "      <td>F</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>01060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6039</th>\n",
       "      <td>6040</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>6</td>\n",
       "      <td>11106</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6040 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0  1   2   3      4\n",
       "0        1  F   1  10  48067\n",
       "1        2  M  56  16  70072\n",
       "2        3  M  25  15  55117\n",
       "3        4  M  45   7  02460\n",
       "4        5  M  25  20  55455\n",
       "...    ... ..  ..  ..    ...\n",
       "6035  6036  F  25  15  32603\n",
       "6036  6037  F  45   1  76006\n",
       "6037  6038  F  56   1  14706\n",
       "6038  6039  F  45   0  01060\n",
       "6039  6040  M  25   6  11106\n",
       "\n",
       "[6040 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "postal-recorder",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = pd.read_csv('ml-1m/ratings.dat', sep='::', header= None, engine='python', encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fabulous-bargain",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>978300760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>661</td>\n",
       "      <td>3</td>\n",
       "      <td>978302109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>914</td>\n",
       "      <td>3</td>\n",
       "      <td>978301968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3408</td>\n",
       "      <td>4</td>\n",
       "      <td>978300275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2355</td>\n",
       "      <td>5</td>\n",
       "      <td>978824291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000204</th>\n",
       "      <td>6040</td>\n",
       "      <td>1091</td>\n",
       "      <td>1</td>\n",
       "      <td>956716541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000205</th>\n",
       "      <td>6040</td>\n",
       "      <td>1094</td>\n",
       "      <td>5</td>\n",
       "      <td>956704887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000206</th>\n",
       "      <td>6040</td>\n",
       "      <td>562</td>\n",
       "      <td>5</td>\n",
       "      <td>956704746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000207</th>\n",
       "      <td>6040</td>\n",
       "      <td>1096</td>\n",
       "      <td>4</td>\n",
       "      <td>956715648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000208</th>\n",
       "      <td>6040</td>\n",
       "      <td>1097</td>\n",
       "      <td>4</td>\n",
       "      <td>956715569</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000209 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0     1  2          3\n",
       "0           1  1193  5  978300760\n",
       "1           1   661  3  978302109\n",
       "2           1   914  3  978301968\n",
       "3           1  3408  4  978300275\n",
       "4           1  2355  5  978824291\n",
       "...       ...   ... ..        ...\n",
       "1000204  6040  1091  1  956716541\n",
       "1000205  6040  1094  5  956704887\n",
       "1000206  6040   562  5  956704746\n",
       "1000207  6040  1096  4  956715648\n",
       "1000208  6040  1097  4  956715569\n",
       "\n",
       "[1000209 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greatest-begin",
   "metadata": {},
   "source": [
    "### Preparing the training set and the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "alpha-challenge",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = pd.read_csv('ml-100k/u1.base', delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dimensional-notebook",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>1.1</th>\n",
       "      <th>5</th>\n",
       "      <th>874965758</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>876893171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>878542960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>876893119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>889751712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>875071561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79994</th>\n",
       "      <td>943</td>\n",
       "      <td>1067</td>\n",
       "      <td>2</td>\n",
       "      <td>875501756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79995</th>\n",
       "      <td>943</td>\n",
       "      <td>1074</td>\n",
       "      <td>4</td>\n",
       "      <td>888640250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79996</th>\n",
       "      <td>943</td>\n",
       "      <td>1188</td>\n",
       "      <td>3</td>\n",
       "      <td>888640250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79997</th>\n",
       "      <td>943</td>\n",
       "      <td>1228</td>\n",
       "      <td>3</td>\n",
       "      <td>888640275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79998</th>\n",
       "      <td>943</td>\n",
       "      <td>1330</td>\n",
       "      <td>3</td>\n",
       "      <td>888692465</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>79999 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         1   1.1  5  874965758\n",
       "0        1     2  3  876893171\n",
       "1        1     3  4  878542960\n",
       "2        1     4  3  876893119\n",
       "3        1     5  3  889751712\n",
       "4        1     7  4  875071561\n",
       "...    ...   ... ..        ...\n",
       "79994  943  1067  2  875501756\n",
       "79995  943  1074  4  888640250\n",
       "79996  943  1188  3  888640250\n",
       "79997  943  1228  3  888640275\n",
       "79998  943  1330  3  888692465\n",
       "\n",
       "[79999 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "frank-router",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = np.array(training_set, dtype='int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "lightweight-acrobat",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[        1,         2,         3, 876893171],\n",
       "       [        1,         3,         4, 878542960],\n",
       "       [        1,         4,         3, 876893119],\n",
       "       ...,\n",
       "       [      943,      1188,         3, 888640250],\n",
       "       [      943,      1228,         3, 888640275],\n",
       "       [      943,      1330,         3, 888692465]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "combined-holocaust",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = pd.read_csv('ml-100k/u1.test', delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "objective-alaska",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>6</th>\n",
       "      <th>5</th>\n",
       "      <th>887431973</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>875693118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>878542960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>874965706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>875073198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>887431883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19994</th>\n",
       "      <td>458</td>\n",
       "      <td>648</td>\n",
       "      <td>4</td>\n",
       "      <td>886395899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>458</td>\n",
       "      <td>1101</td>\n",
       "      <td>4</td>\n",
       "      <td>886397931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>459</td>\n",
       "      <td>934</td>\n",
       "      <td>3</td>\n",
       "      <td>879563639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>460</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>882912371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>462</td>\n",
       "      <td>682</td>\n",
       "      <td>5</td>\n",
       "      <td>886365231</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19999 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         1     6  5  887431973\n",
       "0        1    10  3  875693118\n",
       "1        1    12  5  878542960\n",
       "2        1    14  5  874965706\n",
       "3        1    17  3  875073198\n",
       "4        1    20  4  887431883\n",
       "...    ...   ... ..        ...\n",
       "19994  458   648  4  886395899\n",
       "19995  458  1101  4  886397931\n",
       "19996  459   934  3  879563639\n",
       "19997  460    10  3  882912371\n",
       "19998  462   682  5  886365231\n",
       "\n",
       "[19999 rows x 4 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "russian-sleeve",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = np.array(test_set, dtype='int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "typical-civilization",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[        1,        10,         3, 875693118],\n",
       "       [        1,        12,         5, 878542960],\n",
       "       [        1,        14,         5, 874965706],\n",
       "       ...,\n",
       "       [      459,       934,         3, 879563639],\n",
       "       [      460,        10,         3, 882912371],\n",
       "       [      462,       682,         5, 886365231]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hired-dryer",
   "metadata": {},
   "source": [
    "### Getting the number of users and movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "recognized-honey",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_users = int(max(max(training_set[:,0]), max(test_set[:,0])))\n",
    "nb_movies = int(max(max(training_set[:,1]), max(test_set[:,1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "perfect-commerce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "943"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "minor-armstrong",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1682"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_movies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "streaming-channel",
   "metadata": {},
   "source": [
    "### Converting the data into an array with users in lines and movies in columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "absolute-progressive",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to do this\n",
    "def convert(data):\n",
    "    \"\"\"\n",
    "    Create an array to show user ID in line and movies in columns.\n",
    "    \"\"\"\n",
    "    new_data = []\n",
    "    for id_users in range(1, nb_users+1):\n",
    "        id_movies = data[:,1][data[:,0]==id_users]\n",
    "        id_ratings = data[:,2][data[:,0]==id_users]\n",
    "        ratings = np.zeros(nb_movies)\n",
    "        ratings[id_movies-1] = id_ratings\n",
    "        new_data.append(list(ratings))\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "abstract-tolerance",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = convert(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "female-diana",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = convert(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "limiting-employee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "943"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "inclusive-retail",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "943"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "large-conference",
   "metadata": {},
   "source": [
    "### Converting the data into Torch tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "established-experience",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = torch.FloatTensor(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "solar-appendix",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = torch.FloatTensor(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "facial-milan",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 3., 4.,  ..., 0., 0., 0.],\n",
       "        [4., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [5., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 5., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "spiritual-million",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reflected-knock",
   "metadata": {},
   "source": [
    "## 4. Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "specified-playback",
   "metadata": {},
   "source": [
    "### Create the architecture of the Neural Network\n",
    "\n",
    "We need to create a class for the AutoEncoder model. We are using a class not only because it is convenient for making an object with many attributes and methods, but most important we are using inheritance from PyTorch.\n",
    "Inheritance is we are going to build a class called SAE(stacked-autoencoder-engine), and it will be the child class of an existing parent class in PyTorch called Module. To do this is that we can use all the modeuls and functions from the parent class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "varied-arkansas",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a child class SAE\n",
    "class SAE(nn.Module):\n",
    "    def __init__(self,):\n",
    "        super(SAE, self).__init__()\n",
    "        \n",
    "        # the first full connection layer related to the autoencoder object\n",
    "        self.fc1 = nn.Linear(nb_movies, 20)\n",
    "        \n",
    "        # the second full connection layer\n",
    "        self.fc2 = nn.Linear(20, 10)\n",
    "        \n",
    "        # the third full connection layer\n",
    "        self.fc3 = nn.Linear(10, 20)\n",
    "        \n",
    "        # the fourth full connection layer (output layer)\n",
    "        self.fc4 = nn.Linear(20, nb_movies)\n",
    "        \n",
    "        # Define activation function (we use sigmoid function)\n",
    "        self.activation = nn.Sigmoid()\n",
    "        \n",
    "    # the encoding function    \n",
    "    def forward(self, x):\n",
    "        # x: the input vector\n",
    "        x = self.activation(self.fc1(x))\n",
    "        x = self.activation(self.fc2(x))\n",
    "        x = self.activation(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "forbidden-boxing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a object of SAE class\n",
    "sae = SAE()\n",
    "\n",
    "# Define a loss measurement (we use rmse)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Choose an optimizer (we use RMSprop)\n",
    "optimizer = optim.RMSprop(sae.parameters(), lr=0.01, weight_decay=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ongoing-disney",
   "metadata": {},
   "source": [
    "### Train the SAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "listed-story",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the epoch\n",
    "nb_epoch = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "adaptive-chester",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 loss: tensor(1.7646)\n",
      "epoch: 2 loss: tensor(1.0966)\n",
      "epoch: 3 loss: tensor(1.0537)\n",
      "epoch: 4 loss: tensor(1.0384)\n",
      "epoch: 5 loss: tensor(1.0307)\n",
      "epoch: 6 loss: tensor(1.0265)\n",
      "epoch: 7 loss: tensor(1.0239)\n",
      "epoch: 8 loss: tensor(1.0219)\n",
      "epoch: 9 loss: tensor(1.0208)\n",
      "epoch: 10 loss: tensor(1.0196)\n",
      "epoch: 11 loss: tensor(1.0187)\n",
      "epoch: 12 loss: tensor(1.0186)\n",
      "epoch: 13 loss: tensor(1.0178)\n",
      "epoch: 14 loss: tensor(1.0178)\n",
      "epoch: 15 loss: tensor(1.0172)\n",
      "epoch: 16 loss: tensor(1.0171)\n",
      "epoch: 17 loss: tensor(1.0167)\n",
      "epoch: 18 loss: tensor(1.0165)\n",
      "epoch: 19 loss: tensor(1.0165)\n",
      "epoch: 20 loss: tensor(1.0162)\n",
      "epoch: 21 loss: tensor(1.0161)\n",
      "epoch: 22 loss: tensor(1.0161)\n",
      "epoch: 23 loss: tensor(1.0160)\n",
      "epoch: 24 loss: tensor(1.0157)\n",
      "epoch: 25 loss: tensor(1.0158)\n",
      "epoch: 26 loss: tensor(1.0155)\n",
      "epoch: 27 loss: tensor(1.0155)\n",
      "epoch: 28 loss: tensor(1.0150)\n",
      "epoch: 29 loss: tensor(1.0124)\n",
      "epoch: 30 loss: tensor(1.0112)\n",
      "epoch: 31 loss: tensor(1.0102)\n",
      "epoch: 32 loss: tensor(1.0072)\n",
      "epoch: 33 loss: tensor(1.0080)\n",
      "epoch: 34 loss: tensor(1.0024)\n",
      "epoch: 35 loss: tensor(1.0025)\n",
      "epoch: 36 loss: tensor(1.0000)\n",
      "epoch: 37 loss: tensor(0.9993)\n",
      "epoch: 38 loss: tensor(0.9944)\n",
      "epoch: 39 loss: tensor(0.9965)\n",
      "epoch: 40 loss: tensor(0.9902)\n",
      "epoch: 41 loss: tensor(0.9895)\n",
      "epoch: 42 loss: tensor(0.9877)\n",
      "epoch: 43 loss: tensor(0.9883)\n",
      "epoch: 44 loss: tensor(0.9844)\n",
      "epoch: 45 loss: tensor(0.9850)\n",
      "epoch: 46 loss: tensor(0.9824)\n",
      "epoch: 47 loss: tensor(0.9784)\n",
      "epoch: 48 loss: tensor(0.9766)\n",
      "epoch: 49 loss: tensor(0.9789)\n",
      "epoch: 50 loss: tensor(0.9730)\n",
      "epoch: 51 loss: tensor(0.9757)\n",
      "epoch: 52 loss: tensor(0.9706)\n",
      "epoch: 53 loss: tensor(0.9721)\n",
      "epoch: 54 loss: tensor(0.9698)\n",
      "epoch: 55 loss: tensor(0.9737)\n",
      "epoch: 56 loss: tensor(0.9762)\n",
      "epoch: 57 loss: tensor(0.9732)\n",
      "epoch: 58 loss: tensor(0.9703)\n",
      "epoch: 59 loss: tensor(0.9722)\n",
      "epoch: 60 loss: tensor(0.9673)\n",
      "epoch: 61 loss: tensor(0.9649)\n",
      "epoch: 62 loss: tensor(0.9635)\n",
      "epoch: 63 loss: tensor(0.9626)\n",
      "epoch: 64 loss: tensor(0.9604)\n",
      "epoch: 65 loss: tensor(0.9585)\n",
      "epoch: 66 loss: tensor(0.9550)\n",
      "epoch: 67 loss: tensor(0.9543)\n",
      "epoch: 68 loss: tensor(0.9522)\n",
      "epoch: 69 loss: tensor(0.9548)\n",
      "epoch: 70 loss: tensor(0.9518)\n",
      "epoch: 71 loss: tensor(0.9534)\n",
      "epoch: 72 loss: tensor(0.9513)\n",
      "epoch: 73 loss: tensor(0.9506)\n",
      "epoch: 74 loss: tensor(0.9491)\n",
      "epoch: 75 loss: tensor(0.9485)\n",
      "epoch: 76 loss: tensor(0.9471)\n",
      "epoch: 77 loss: tensor(0.9506)\n",
      "epoch: 78 loss: tensor(0.9462)\n",
      "epoch: 79 loss: tensor(0.9460)\n",
      "epoch: 80 loss: tensor(0.9439)\n",
      "epoch: 81 loss: tensor(0.9441)\n",
      "epoch: 82 loss: tensor(0.9423)\n",
      "epoch: 83 loss: tensor(0.9424)\n",
      "epoch: 84 loss: tensor(0.9411)\n",
      "epoch: 85 loss: tensor(0.9414)\n",
      "epoch: 86 loss: tensor(0.9397)\n",
      "epoch: 87 loss: tensor(0.9396)\n",
      "epoch: 88 loss: tensor(0.9387)\n",
      "epoch: 89 loss: tensor(0.9387)\n",
      "epoch: 90 loss: tensor(0.9377)\n",
      "epoch: 91 loss: tensor(0.9375)\n",
      "epoch: 92 loss: tensor(0.9363)\n",
      "epoch: 93 loss: tensor(0.9363)\n",
      "epoch: 94 loss: tensor(0.9354)\n",
      "epoch: 95 loss: tensor(0.9357)\n",
      "epoch: 96 loss: tensor(0.9346)\n",
      "epoch: 97 loss: tensor(0.9343)\n",
      "epoch: 98 loss: tensor(0.9337)\n",
      "epoch: 99 loss: tensor(0.9339)\n",
      "epoch: 100 loss: tensor(0.9331)\n",
      "epoch: 101 loss: tensor(0.9330)\n",
      "epoch: 102 loss: tensor(0.9323)\n",
      "epoch: 103 loss: tensor(0.9315)\n",
      "epoch: 104 loss: tensor(0.9311)\n",
      "epoch: 105 loss: tensor(0.9311)\n",
      "epoch: 106 loss: tensor(0.9309)\n",
      "epoch: 107 loss: tensor(0.9306)\n",
      "epoch: 108 loss: tensor(0.9305)\n",
      "epoch: 109 loss: tensor(0.9299)\n",
      "epoch: 110 loss: tensor(0.9292)\n",
      "epoch: 111 loss: tensor(0.9294)\n",
      "epoch: 112 loss: tensor(0.9291)\n",
      "epoch: 113 loss: tensor(0.9284)\n",
      "epoch: 114 loss: tensor(0.9283)\n",
      "epoch: 115 loss: tensor(0.9286)\n",
      "epoch: 116 loss: tensor(0.9279)\n",
      "epoch: 117 loss: tensor(0.9281)\n",
      "epoch: 118 loss: tensor(0.9274)\n",
      "epoch: 119 loss: tensor(0.9273)\n",
      "epoch: 120 loss: tensor(0.9266)\n",
      "epoch: 121 loss: tensor(0.9264)\n",
      "epoch: 122 loss: tensor(0.9261)\n",
      "epoch: 123 loss: tensor(0.9257)\n",
      "epoch: 124 loss: tensor(0.9252)\n",
      "epoch: 125 loss: tensor(0.9254)\n",
      "epoch: 126 loss: tensor(0.9251)\n",
      "epoch: 127 loss: tensor(0.9245)\n",
      "epoch: 128 loss: tensor(0.9241)\n",
      "epoch: 129 loss: tensor(0.9238)\n",
      "epoch: 130 loss: tensor(0.9236)\n",
      "epoch: 131 loss: tensor(0.9237)\n",
      "epoch: 132 loss: tensor(0.9230)\n",
      "epoch: 133 loss: tensor(0.9223)\n",
      "epoch: 134 loss: tensor(0.9222)\n",
      "epoch: 135 loss: tensor(0.9219)\n",
      "epoch: 136 loss: tensor(0.9214)\n",
      "epoch: 137 loss: tensor(0.9217)\n",
      "epoch: 138 loss: tensor(0.9208)\n",
      "epoch: 139 loss: tensor(0.9206)\n",
      "epoch: 140 loss: tensor(0.9205)\n",
      "epoch: 141 loss: tensor(0.9205)\n",
      "epoch: 142 loss: tensor(0.9199)\n",
      "epoch: 143 loss: tensor(0.9198)\n",
      "epoch: 144 loss: tensor(0.9195)\n",
      "epoch: 145 loss: tensor(0.9194)\n",
      "epoch: 146 loss: tensor(0.9191)\n",
      "epoch: 147 loss: tensor(0.9191)\n",
      "epoch: 148 loss: tensor(0.9187)\n",
      "epoch: 149 loss: tensor(0.9186)\n",
      "epoch: 150 loss: tensor(0.9182)\n",
      "epoch: 151 loss: tensor(0.9183)\n",
      "epoch: 152 loss: tensor(0.9177)\n",
      "epoch: 153 loss: tensor(0.9176)\n",
      "epoch: 154 loss: tensor(0.9174)\n",
      "epoch: 155 loss: tensor(0.9172)\n",
      "epoch: 156 loss: tensor(0.9167)\n",
      "epoch: 157 loss: tensor(0.9167)\n",
      "epoch: 158 loss: tensor(0.9164)\n",
      "epoch: 159 loss: tensor(0.9166)\n",
      "epoch: 160 loss: tensor(0.9159)\n",
      "epoch: 161 loss: tensor(0.9160)\n",
      "epoch: 162 loss: tensor(0.9155)\n",
      "epoch: 163 loss: tensor(0.9158)\n",
      "epoch: 164 loss: tensor(0.9151)\n",
      "epoch: 165 loss: tensor(0.9159)\n",
      "epoch: 166 loss: tensor(0.9150)\n",
      "epoch: 167 loss: tensor(0.9153)\n",
      "epoch: 168 loss: tensor(0.9144)\n",
      "epoch: 169 loss: tensor(0.9150)\n",
      "epoch: 170 loss: tensor(0.9141)\n",
      "epoch: 171 loss: tensor(0.9144)\n",
      "epoch: 172 loss: tensor(0.9140)\n",
      "epoch: 173 loss: tensor(0.9139)\n",
      "epoch: 174 loss: tensor(0.9133)\n",
      "epoch: 175 loss: tensor(0.9135)\n",
      "epoch: 176 loss: tensor(0.9134)\n",
      "epoch: 177 loss: tensor(0.9137)\n",
      "epoch: 178 loss: tensor(0.9132)\n",
      "epoch: 179 loss: tensor(0.9133)\n",
      "epoch: 180 loss: tensor(0.9125)\n",
      "epoch: 181 loss: tensor(0.9129)\n",
      "epoch: 182 loss: tensor(0.9126)\n",
      "epoch: 183 loss: tensor(0.9140)\n",
      "epoch: 184 loss: tensor(0.9154)\n",
      "epoch: 185 loss: tensor(0.9125)\n",
      "epoch: 186 loss: tensor(0.9122)\n",
      "epoch: 187 loss: tensor(0.9121)\n",
      "epoch: 188 loss: tensor(0.9121)\n",
      "epoch: 189 loss: tensor(0.9121)\n",
      "epoch: 190 loss: tensor(0.9115)\n",
      "epoch: 191 loss: tensor(0.9113)\n",
      "epoch: 192 loss: tensor(0.9109)\n",
      "epoch: 193 loss: tensor(0.9110)\n",
      "epoch: 194 loss: tensor(0.9106)\n",
      "epoch: 195 loss: tensor(0.9106)\n",
      "epoch: 196 loss: tensor(0.9103)\n",
      "epoch: 197 loss: tensor(0.9107)\n",
      "epoch: 198 loss: tensor(0.9102)\n",
      "epoch: 199 loss: tensor(0.9102)\n",
      "epoch: 200 loss: tensor(0.9099)\n"
     ]
    }
   ],
   "source": [
    "# Loop over epochs and observations(users)\n",
    "for epoch in range(1, nb_epoch+1):\n",
    "    # loss error\n",
    "    train_loss = 0\n",
    "    #the number of users that rated at least one movie\n",
    "    s=0.\n",
    "    \n",
    "    for id_user in range(nb_users):\n",
    "        # We need another dimension for the batch of inputs, so use Variable funciton\n",
    "        input = Variable(training_set[id_user]).unsqueeze(0)\n",
    "        target = input.clone()\n",
    "        \n",
    "        # We only consider the users that rate at least one movie, that will save some memories.\n",
    "        if torch.sum(target.data > 0) > 0:\n",
    "            output = sae(input)\n",
    "            # To make sure that the gradient is computer only with respect to the input but not the target\n",
    "            target.require_grad = False\n",
    "            # We don't want the unrated movies to be account in the computation of error, and impact the weights \n",
    "            output[target == 0] = 0\n",
    "            loss = criterion(output, target)\n",
    "            \n",
    "            # mean_corrector represents the average of the error but by only considering the movies that were rated.\n",
    "            # add 1e-10 is for the math reason that this denominator won't be zero and cause error of infinity computation\n",
    "            mean_corrector = nb_movies/float(torch.sum(target.data > 0) + 1e-10)\n",
    "            \n",
    "            # Call the backward method\n",
    "            loss.backward()\n",
    "            \n",
    "            # add up the train loss (the rmse)\n",
    "            train_loss += np.sqrt(loss.data * mean_corrector)\n",
    "            \n",
    "            # increment the count\n",
    "            s += 1.\n",
    "            \n",
    "            # optimizer\n",
    "            optimizer.step()\n",
    "            \n",
    "    # print what happen in the function\n",
    "    print('epoch: ' + str(epoch) + ' loss: ' + str(train_loss/s))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outer-recipient",
   "metadata": {},
   "source": [
    "## 5. Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "statistical-journal",
   "metadata": {},
   "source": [
    "### Test the SAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "perfect-stake",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(0.9478)\n"
     ]
    }
   ],
   "source": [
    "# loss error\n",
    "test_loss = 0\n",
    "#the number of users that rated at least one movie\n",
    "s=0.\n",
    "\n",
    "for id_user in range(nb_users):\n",
    "    # We need to take the input of the specific user cause we are comparing the user predicting unrated movies\n",
    "    input = Variable(training_set[id_user]).unsqueeze(0)\n",
    "    target = Variable(test_set[id_user]).unsqueeze(0)\n",
    "\n",
    "    # Test the prediction\n",
    "    if torch.sum(target.data > 0) > 0:\n",
    "        output = sae(input)\n",
    "        # To make sure that the gradient is computer only with respect to the input but not the target\n",
    "        target.require_grad = False\n",
    "        \n",
    "        output[target == 0] = 0\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        mean_corrector = nb_movies/float(torch.sum(target.data > 0) + 1e-10)\n",
    "\n",
    "        # add up the test loss (the rmse)\n",
    "        test_loss += np.sqrt(loss.data * mean_corrector)\n",
    "\n",
    "        # increment the count\n",
    "        s += 1.\n",
    "\n",
    "# print what happen in the function\n",
    "print('loss: ' + str(test_loss/s))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
